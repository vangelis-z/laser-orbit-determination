{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Orbit determination example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CAUTION: this is only an example, there is no guarantee that all computations are 100% correct, nor that this example won't break with future Orekit versions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This notebook does the following:\n",
    "* Download an orbit first guess from SpaceTrack\n",
    "* Download laser ranging data\n",
    "* Feed the data to Orekit\n",
    "* Estimate the orbit\n",
    "* Propagate and compare the orbit to the first guess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two types of laser ranging data can be chosen (see below):\n",
    "\n",
    "* Normal point data: https://ilrs.cddis.eosdis.nasa.gov/data_and_products/data/npt/index.html\n",
    "* Full rate data: https://ilrs.cddis.eosdis.nasa.gov/data_and_products/data/frt/index.html\n",
    "    * This will improve the orbit estimation\n",
    "    * Caution, this format involves large quantities of data\n",
    "    * Caution 2, this data is unfiltered, therefore there can be a superposition of two range curves if two retro-reflectors on the satellite are visible by the station at the same time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OD parameters\n",
    "First, some parameters need to be defined for the orbit determination:\n",
    "* Satellite ID in NORAD, COSPAR and SIC code format. These IDs can be found here: https://edc.dgfi.tum.de/en/satellites/\n",
    "* Spacecraft mass: important for the drag term\n",
    "* Measurement weights: used to weight certain measurements more than others during the orbit estimation. Here, we only have range measurements and we do not know the confidence associated to these measurements, so all weights are identical\n",
    "* OD date: date at which the orbit will be estimated. \n",
    "* Data collection duration: for example, if equals 2 days, the laser data from the 2 days before the OD date will be used to estimate the orbit. This value is an important trade-off for the quality of the orbit determination:\n",
    "    * The longer the duration, the more ranging data is available, which can increase the quality of the estimation\n",
    "    * The longer the duration, the longer the orbit must be propagated, and the higher the covariance because of the orbit perturbations such as the gravity field, drag, Sun, Moon, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Satellite parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sat_list = {\n",
    "    'envisat': {\n",
    "        'norad_id': 27386,  # For Space-Track TLE queries\n",
    "        'cospar_id': '0200901',  # For laser ranging data queries\n",
    "        'sic_id': '6179',  # For writing in CPF files\n",
    "        'mass': 8000.0, # kg; TODO: compute proper value\n",
    "        'cross_section': 100.0, # m2; TODO: compute proper value\n",
    "        'cd': 2.0, # TODO: compute proper value\n",
    "        'cr': 1.0  # TODO: compute proper value\n",
    "    },\n",
    "    'lageos2': {\n",
    "        'norad_id': 22195,\n",
    "        'cospar_id': '9207002',\n",
    "        'sic_id': '5986',\n",
    "        'mass': 405.0, # kg\n",
    "        'cross_section': 0.2827, # m2\n",
    "        'cd': 2.0, # TODO: compute proper value\n",
    "        'cr': 1.0  # TODO: compute proper value\n",
    "    },\n",
    "    'technosat': {\n",
    "        'norad_id': 42829,\n",
    "        'cospar_id': '1704205',\n",
    "        'sic_id': '6203',\n",
    "        'mass': 20.0, # kg\n",
    "        'cross_section': 0.10, # m2,\n",
    "        'cd': 2.0, # TODO: compute proper value\n",
    "        'cr': 1.0  # TODO: compute proper value\n",
    "    },\n",
    "    'snet1': {\n",
    "        'norad_id': 43189,\n",
    "        'cospar_id': '1801410',\n",
    "        'sic_id': '6204',\n",
    "        'mass': 8.0, # kg\n",
    "        'cross_section': 0.07,\n",
    "        'cd': 2.0, # TODO: compute proper value\n",
    "        'cr': 1.0  # TODO: compute proper value\n",
    "    }\n",
    "}\n",
    "\n",
    "sc_name = 'lageos2'  # Change the name to select a different satellite in the dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Orbit determination parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "NPT: Normal point data. Recommended option. The data is pre-filtered by the laser data providers\n",
    "FRD: Full-rate data. Warning, these are a lot of data points (potentially tens of thousands per day),\n",
    "    the execution time could be greatly increased\n",
    "\"\"\"\n",
    "laser_data_type = 'NPT'\n",
    "\n",
    "range_weight = 1.0 # Will be normalized later (i.e divided by the number of observations)\n",
    "range_sigma = 1.0 # Estimated covariance of the range measurements, in meters\n",
    "\n",
    "import numpy as np\n",
    "az_weight = 0.1  # Do not weigh the Az/El measurements too much because they are much less accurate than ranges\n",
    "el_weight = 0.1\n",
    "az_sigma = float(np.deg2rad(0.01))\n",
    "el_sigma = float(np.deg2rad(0.01))\n",
    "\n",
    "from datetime import datetime\n",
    "odDate = datetime(2019, 12, 5) # Beginning of the orbit determination\n",
    "collectionDuration = 2 # days\n",
    "from datetime import timedelta\n",
    "startCollectionDate = odDate + timedelta(days=-collectionDuration)\n",
    "\n",
    "# Orbit propagator parameters\n",
    "prop_min_step = 0.001 # s\n",
    "prop_max_step = 300.0 # s\n",
    "prop_position_error = 10.0 # m\n",
    "\n",
    "# Estimator parameters\n",
    "estimator_position_scale = 1.0 # m\n",
    "estimator_convergence_thres = 1e-2\n",
    "estimator_max_iterations = 25\n",
    "estimator_max_evaluations = 35"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API credentials\n",
    "The following sets up accounts for SpaceTrack (for orbit data) and the EDC API (for laser ranging data).\n",
    "* A SpaceTrack account is required, it can be created for free at: https://www.space-track.org/auth/createAccount\n",
    "* An EDC account is required, it can be created for free at: https://edc.dgfi.tum.de/en/register/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Space-Track\n",
    "identity_st = input('Enter SpaceTrack username')\n",
    "import getpass\n",
    "password_st = getpass.getpass(prompt='Enter SpaceTrack password for account {}'.format(identity_st))\n",
    "import spacetrack.operators as op\n",
    "from spacetrack import SpaceTrackClient\n",
    "st = SpaceTrackClient(identity=identity_st, password=password_st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDC API\n",
    "username_edc = input('Enter EDC API username')\n",
    "password_edc = getpass.getpass(prompt='Enter EDC API password for account {}'.format(username_edc)) # You will get prompted for your password\n",
    "url = 'https://edc.dgfi.tum.de/api/v1/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up models\n",
    "Initializing Orekit and JVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import jdk4py\n",
    "\n",
    "if \"JAVA_HOME\" not in os.environ:\n",
    "    os.environ[\"JAVA_HOME\"] = str(jdk4py.JAVA_HOME)\n",
    "\n",
    "import orekit_jpype\n",
    "orekit_jpype.initVM()\n",
    "\n",
    "orekit_jpype.pyhelpers.setup_orekit_data(from_pip_library=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up Orekit frames and models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from org.orekit.utils import Constants as orekit_constants\n",
    "\n",
    "from org.orekit.frames import FramesFactory\n",
    "from org.orekit.utils import IERSConventions\n",
    "tod = FramesFactory.getTOD(IERSConventions.IERS_2010, False) # Taking tidal effects into account when interpolating EOP parameters\n",
    "gcrf = FramesFactory.getGCRF()\n",
    "itrf = FramesFactory.getITRF(IERSConventions.IERS_2010, False)\n",
    "# Selecting frames to use for OD\n",
    "eci = gcrf\n",
    "ecef = itrf\n",
    "\n",
    "from org.orekit.models.earth import ReferenceEllipsoid\n",
    "wgs84Ellipsoid = ReferenceEllipsoid.getWgs84(ecef)\n",
    "from org.orekit.bodies import CelestialBodyFactory\n",
    "moon = CelestialBodyFactory.getMoon()\n",
    "sun = CelestialBodyFactory.getSun()\n",
    "\n",
    "from org.orekit.time import AbsoluteDate, TimeScalesFactory\n",
    "utc = TimeScalesFactory.getUTC()\n",
    "mjd_utc_epoch = AbsoluteDate(1858, 11, 17, 0, 0, 0.0, utc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import station data from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stationFile = 'SLRF2020_POS+VEL_2023.10.02.snx'\n",
    "stationEccFile = 'ecc_xyz.snx'\n",
    "from org.orekit.files.sinex import SinexLoader, Station\n",
    "from org.orekit.data import DataSource\n",
    "stations_map = SinexLoader(DataSource(stationFile)).getStations()\n",
    "ecc_map = SinexLoader(DataSource(stationEccFile)).getStations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting the station data to Orekit GroundStation objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from org.orekit.estimation.measurements import GroundStation\n",
    "from org.orekit.frames import TopocentricFrame\n",
    "\n",
    "import pandas as pd\n",
    "from orekit_jpype.pyhelpers import datetime_to_absolutedate\n",
    "import numpy as np\n",
    "\n",
    "station_keys = stations_map.keySet()\n",
    "\n",
    "n_errors = 0\n",
    "station_df = pd.DataFrame(columns=['lat_deg', 'lon_deg', 'alt_m', 'GroundStation'])\n",
    "for key in station_keys:\n",
    "    station_data = stations_map.get(key)\n",
    "    ecc_data = ecc_map.get(key)\n",
    "    if ecc_data.getEccRefSystem() != Station.ReferenceSystem.XYZ:\n",
    "        print('Error, eccentricity coordinate system not XYZ')\n",
    "\n",
    "    epoch_velocity = station_data.getEpoch()\n",
    "    durationSinceEpoch = datetime_to_absolutedate(odDate).durationFrom(epoch_velocity)  # seconds\n",
    "\n",
    "    # Computing current station position using velocity data\n",
    "    station_pos_at_epoch = station_data.getPosition()\n",
    "    vel = station_data.getVelocity()  # m/s\n",
    "    station_pos_current = station_pos_at_epoch.add(vel.scalarMultiply(durationSinceEpoch))\n",
    "\n",
    "    # Adding eccentricity\n",
    "    try:\n",
    "        station_pos_current = station_pos_current.add(ecc_data.getEccentricities(datetime_to_absolutedate(odDate)))\n",
    "        # Converting to ground station object\n",
    "        geodeticPoint = wgs84Ellipsoid.transform(station_pos_current, itrf, datetime_to_absolutedate(odDate))\n",
    "        lon_deg = np.rad2deg(geodeticPoint.getLongitude())\n",
    "        lat_deg = np.rad2deg(geodeticPoint.getLatitude())\n",
    "        alt_m = geodeticPoint.getAltitude()\n",
    "        topocentricFrame = TopocentricFrame(wgs84Ellipsoid, geodeticPoint, key)\n",
    "        groundStation = GroundStation(topocentricFrame)\n",
    "        station_df.loc[key] = [lat_deg, lon_deg, alt_m, groundStation]\n",
    "    except:\n",
    "        # And exception is thrown when the odDate is not in the date range of the eccentricity entry for this station\n",
    "        # This is simply for stations which do not exist anymore at odDate\n",
    "        n_errors += 1\n",
    "\n",
    "station_df = station_df.sort_index()\n",
    "display(station_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The orbit determination needs a first guess. For this, we use Two-Line Elements. Retrieving the latest TLE prior to the beginning of the orbit determination. It is important to have a \"fresh\" TLE, because the newer the TLE, the better the orbit estimation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawTle = st.tle(norad_cat_id=sat_list[sc_name]['norad_id'], epoch='<{}'.format(odDate), orderby='epoch desc', limit=1, format='tle')\n",
    "tleLine1 = rawTle.split('\\n')[0]\n",
    "tleLine2 = rawTle.split('\\n')[1]\n",
    "print(tleLine1)\n",
    "print(tleLine2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up the propagator from the initial TLEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from org.orekit.propagation.analytical.tle import TLE\n",
    "orekitTle = TLE(tleLine1, tleLine2)\n",
    "\n",
    "from org.orekit.attitudes import NadirPointing, FrameAlignedProvider\n",
    "pointing = FrameAlignedProvider(eci)\n",
    "\n",
    "from org.orekit.propagation.analytical.tle import SGP4\n",
    "sgp4Propagator = SGP4(orekitTle, pointing, sat_list[sc_name]['mass'])\n",
    "\n",
    "tleInitialState = sgp4Propagator.getInitialState()\n",
    "tleEpoch = tleInitialState.getDate()\n",
    "tleOrbit_TEME = tleInitialState.getOrbit()\n",
    "tlePV_ECI = tleOrbit_TEME.getPVCoordinates(eci)\n",
    "\n",
    "from org.orekit.orbits import CartesianOrbit\n",
    "tleOrbit_ECI = CartesianOrbit(tlePV_ECI, eci, wgs84Ellipsoid.getGM())\n",
    "\n",
    "from org.orekit.propagation.conversion import DormandPrince853IntegratorBuilder\n",
    "integratorBuilder = DormandPrince853IntegratorBuilder(prop_min_step, prop_max_step, prop_position_error)\n",
    "\n",
    "from org.orekit.propagation.conversion import NumericalPropagatorBuilder\n",
    "from org.orekit.orbits import PositionAngleType\n",
    "propagatorBuilder = NumericalPropagatorBuilder(tleOrbit_ECI,\n",
    "                                               integratorBuilder, PositionAngleType.MEAN, estimator_position_scale)\n",
    "propagatorBuilder.setMass(sat_list[sc_name]['mass'])\n",
    "propagatorBuilder.setAttitudeProvider(pointing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding perturbation forces to the propagator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Earth gravity field with degree 64 and order 64\n",
    "from org.orekit.forces.gravity.potential import GravityFieldFactory\n",
    "gravityProvider = GravityFieldFactory.getNormalizedProvider(64, 64)\n",
    "from org.orekit.forces.gravity import HolmesFeatherstoneAttractionModel\n",
    "gravityAttractionModel = HolmesFeatherstoneAttractionModel(ecef, gravityProvider)\n",
    "propagatorBuilder.addForceModel(gravityAttractionModel)\n",
    "\n",
    "# Moon and Sun perturbations\n",
    "from org.orekit.forces.gravity import ThirdBodyAttraction\n",
    "moon_3dbodyattraction = ThirdBodyAttraction(moon)\n",
    "propagatorBuilder.addForceModel(moon_3dbodyattraction)\n",
    "sun_3dbodyattraction = ThirdBodyAttraction(sun)\n",
    "propagatorBuilder.addForceModel(sun_3dbodyattraction)\n",
    "\n",
    "# Solar radiation pressure\n",
    "from org.orekit.forces.radiation import IsotropicRadiationSingleCoefficient\n",
    "isotropicRadiationSingleCoeff = IsotropicRadiationSingleCoefficient(sat_list[sc_name]['cross_section'], sat_list[sc_name]['cr']);\n",
    "from org.orekit.forces.radiation import SolarRadiationPressure\n",
    "solarRadiationPressure = SolarRadiationPressure(sun, wgs84Ellipsoid,\n",
    "                                                isotropicRadiationSingleCoeff)\n",
    "propagatorBuilder.addForceModel(solarRadiationPressure)\n",
    "\n",
    "# Relativity\n",
    "from org.orekit.forces.gravity import Relativity\n",
    "relativity = Relativity(orekit_constants.EIGEN5C_EARTH_MU)\n",
    "propagatorBuilder.addForceModel(relativity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding atmospheric drag to the propagator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Atmospheric drag\n",
    "from org.orekit.models.earth.atmosphere.data import CssiSpaceWeatherData\n",
    "cswl = CssiSpaceWeatherData(\"SpaceWeather-All-v1.2.txt\")\n",
    "\n",
    "from org.orekit.models.earth.atmosphere import NRLMSISE00\n",
    "atmosphere = NRLMSISE00(cswl, sun, wgs84Ellipsoid)\n",
    "#from org.orekit.forces.drag.atmosphere import DTM2000\n",
    "#atmosphere = DTM2000(msafe, sun, wgs84Ellipsoid)\n",
    "from org.orekit.forces.drag import IsotropicDrag\n",
    "isotropicDrag = IsotropicDrag(sat_list[sc_name]['cross_section'], sat_list[sc_name]['cd'])\n",
    "from org.orekit.forces.drag import DragForce\n",
    "dragForce = DragForce(atmosphere, isotropicDrag)\n",
    "propagatorBuilder.addForceModel(dragForce)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up the estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from org.hipparchus.linear import QRDecomposer\n",
    "matrixDecomposer = QRDecomposer(1e-11)\n",
    "from org.hipparchus.optim.nonlinear.vector.leastsquares import GaussNewtonOptimizer\n",
    "optimizer = GaussNewtonOptimizer(matrixDecomposer, False)\n",
    "\n",
    "from org.orekit.estimation.leastsquares import BatchLSEstimator\n",
    "estimator = BatchLSEstimator(optimizer, propagatorBuilder)\n",
    "estimator.setParametersConvergenceThreshold(estimator_convergence_thres)\n",
    "estimator.setMaxIterations(estimator_max_iterations)\n",
    "estimator.setMaxEvaluations(estimator_max_evaluations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetching range data\n",
    "Looking for laser ranging data prior to the OD date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from slrDataUtils import SlrDlManager\n",
    "slr_dl_manager = SlrDlManager(username_edc=username_edc,\n",
    "                     password_edc=password_edc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "laserDatasetList = slr_dl_manager.querySlrData(laser_data_type,\n",
    "                                                sat_list[sc_name]['cospar_id'],\n",
    "                                                startCollectionDate, odDate)\n",
    "display(laserDatasetList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downloading the list of observations to NPT files (in a folder in the gitignore, we don't need to manage these files in git)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slrDataFrame = slr_dl_manager.dlAndParseSlrData(laser_data_type, laserDatasetList, 'slr-data')\n",
    "display(slrDataFrame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding the measurements to the estimator.\n",
    "\n",
    "Update 2024-05-13: The Az/el measurements are commented out but are kept for documentation purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from orekit_jpype.pyhelpers import datetime_to_absolutedate\n",
    "from org.orekit.estimation.measurements import Range, AngularAzEl, ObservableSatellite\n",
    "from org.orekit.models.earth.troposphere import MendesPavlisModel\n",
    "from org.orekit.estimation.measurements.modifiers import RangeTroposphericDelayModifier\n",
    "\n",
    "observableSatellite = ObservableSatellite(0) # Propagator index = 0\n",
    "\n",
    "for receiveTime, slrData in slrDataFrame.iterrows():\n",
    "    if slrData['station-id'] in station_df.index: # Checking if station exists in the stations list, because it might not be up-to-date\n",
    "        if not np.isnan(slrData['range']):  # If this data point contains a valid range measurement\n",
    "            orekitRange = Range(station_df.loc[slrData['station-id'], 'GroundStation'],\n",
    "                                True, # Two-way measurement\n",
    "                                receiveTime,\n",
    "                                slrData['range'],\n",
    "                                range_sigma,\n",
    "                                range_weight,\n",
    "                                observableSatellite\n",
    "                               ) # Uses date of signal reception; https://www.orekit.org/static/apidocs/org/orekit/estimation/measurements/Range.html\n",
    "\n",
    "            range_tropo_delay_modifier = RangeTroposphericDelayModifier(\n",
    "                MendesPavlisModel(slrData['temperature_K'],\n",
    "                                  slrData['pressure_mbar'],\n",
    "                                  slrData['humidity'],\n",
    "                                  slrData['wavelength_microm'])\n",
    "            )\n",
    "            orekitRange.addModifier(range_tropo_delay_modifier)\n",
    "\n",
    "            estimator.addMeasurement(orekitRange)\n",
    "        #if not np.isnan(slrData['az']):  # If this data point contains a valid angles measurement\n",
    "        #    orekitAzEl = AngularAzEl(station_df.loc[slrData['station-id'], 'GroundStation'],\n",
    "        #                            receiveTime,\n",
    "        #                            JArray('double')([slrData['az'], slrData['el']]),\n",
    "        #                            JArray('double')([az_sigma, el_sigma]),\n",
    "        #                            JArray('double')([az_weight, el_weight]),\n",
    "        #                            observableSatellite)\n",
    "        #    estimator.addMeasurement(orekitAzEl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing the OD\n",
    "Estimate the orbit. This step can take a long time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimatedPropagatorArray = estimator.estimate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Propagating the estimated orbit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = 300.0\n",
    "date_start = datetime_to_absolutedate(startCollectionDate)\n",
    "date_start = date_start.shiftedBy(-86400.0)\n",
    "date_end = datetime_to_absolutedate(odDate)\n",
    "date_end = date_end.shiftedBy(86400.0) # Stopping 1 day after OD date\n",
    "\n",
    "# First propagating in ephemeris mode\n",
    "estimatedPropagator = estimatedPropagatorArray[0]\n",
    "estimatedInitialState = estimatedPropagator.getInitialState()\n",
    "actualOdDate = estimatedInitialState.getDate()\n",
    "estimatedPropagator.resetInitialState(estimatedInitialState)\n",
    "eph_generator = estimatedPropagator.getEphemerisGenerator()\n",
    "\n",
    "# Propagating from 1 day before data collection\n",
    "# To 1 week after orbit determination (for CPF generation)\n",
    "estimatedPropagator.propagate(date_start, datetime_to_absolutedate(odDate).shiftedBy(7 * 86400.0))\n",
    "bounded_propagator = eph_generator.getGeneratedEphemeris()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Covariance analysis\n",
    "Creating the LVLH frame, computing the covariance matrix in both TOD and LVLH frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the LVLH frame\n",
    "# It must be associated to the bounded propagator, not the original numerical propagator\n",
    "from org.orekit.frames import LocalOrbitalFrame\n",
    "from org.orekit.frames import LOFType\n",
    "lvlh = LocalOrbitalFrame(eci, LOFType.LVLH, bounded_propagator, 'LVLH')\n",
    "\n",
    "# Getting covariance matrix in ECI frame\n",
    "covMat_eci_java = estimator.getPhysicalCovariances(1.0e-10)\n",
    "\n",
    "# Converting matrix to LVLH frame\n",
    "# Getting an inertial frame aligned with the LVLH frame at this instant\n",
    "# The LVLH is normally not inertial, but this should not affect results too much\n",
    "# Reference: David Vallado, Covariance Transformations for Satellite Flight Dynamics Operations, 2003\n",
    "eci2lvlh_frozen = eci.getTransformTo(lvlh, actualOdDate).freeze()\n",
    "\n",
    "# Computing Jacobian\n",
    "from org.orekit.utils import CartesianDerivativesFilter\n",
    "from orekit_jpype.pyhelpers import JArray_double2D\n",
    "jacobianDoubleArray = JArray_double2D(np.zeros((6, 6)))\n",
    "eci2lvlh_frozen.getJacobian(CartesianDerivativesFilter.USE_PV, jacobianDoubleArray)\n",
    "from org.hipparchus.linear import Array2DRowRealMatrix\n",
    "jacobian = Array2DRowRealMatrix(jacobianDoubleArray)\n",
    "# Applying Jacobian to convert matrix to lvlh\n",
    "covMat_lvlh_java = jacobian.multiply(\n",
    "    covMat_eci_java.multiply(jacobian.transpose()))\n",
    "\n",
    "# Converting the Java matrices to numpy\n",
    "import numpy as np\n",
    "covarianceMat_eci = np.matrix([covMat_eci_java.getRow(iRow)\n",
    "                              for iRow in range(0, covMat_eci_java.getRowDimension())])\n",
    "covarianceMat_lvlh = np.matrix([covMat_lvlh_java.getRow(iRow)\n",
    "                              for iRow in range(0, covMat_lvlh_java.getRowDimension())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing the position and velocity standard deviation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_std_crossTrack = np.sqrt(covarianceMat_lvlh[0,0])\n",
    "pos_std_alongTrack = np.sqrt(covarianceMat_lvlh[1,1])\n",
    "pos_std_outOfPlane = np.sqrt(covarianceMat_lvlh[2,2])\n",
    "print(f'Position std: cross-track {pos_std_crossTrack:.3e} m, along-track {pos_std_alongTrack:.3e} m, out-of-plane {pos_std_outOfPlane:.3e} m')\n",
    "\n",
    "vel_std_crossTrack = np.sqrt(covarianceMat_lvlh[3,3])\n",
    "vel_std_alongTrack = np.sqrt(covarianceMat_lvlh[4,4])\n",
    "vel_std_outOfPlane = np.sqrt(covarianceMat_lvlh[5,5])\n",
    "print(f'Velocity std: cross-track {vel_std_crossTrack:.3e} m/s, along-track {vel_std_alongTrack:.3e} m/s, out-of-plane {vel_std_outOfPlane:.3e} m/s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CCSDS OPM\n",
    "Writing a CCSDS OPM message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sat_properties = {\n",
    "     'mass': sat_list[sc_name]['mass'],\n",
    "     'solar_rad_area': sat_list[sc_name]['cross_section'],\n",
    "     'solar_rad_coeff': sat_list[sc_name]['cd'],\n",
    "     'drag_area': sat_list[sc_name]['cross_section'],\n",
    "     'drag_coeff': sat_list[sc_name]['cr']\n",
    "}\n",
    "\n",
    "from ccsdsUtils import Ccsds\n",
    "ccsds_writer = Ccsds(originator='GOR', object_name=sc_name, object_id=sat_list[sc_name]['norad_id'], sat_properties=sat_properties)\n",
    "\n",
    "pv_eci_init = estimatedInitialState.getPVCoordinates()\n",
    "pos_eci_init = np.array(pv_eci_init.getPosition().toArray())\n",
    "vel_eci_init = np.array(pv_eci_init.getVelocity().toArray())\n",
    "\n",
    "from orekit_jpype.pyhelpers import absolutedate_to_datetime\n",
    "\n",
    "ccsds_writer.write_opm('OPM.txt', absolutedate_to_datetime(actualOdDate), pos_eci_init, vel_eci_init, covarianceMat_eci, 'EARTH', 'GCRF')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing residuals\n",
    "Getting the estimated and measured ranges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "propagatorParameters   = estimator.getPropagatorParametersDrivers(True)\n",
    "measurementsParameters = estimator.getMeasurementsParametersDrivers(True)\n",
    "\n",
    "lastEstimations = estimator.getLastEstimations()\n",
    "valueSet = lastEstimations.values()\n",
    "estimatedMeasurements = valueSet.toArray()\n",
    "keySet = lastEstimations.keySet()\n",
    "realMeasurements = keySet.toArray()\n",
    "\n",
    "from org.orekit.estimation.measurements import EstimatedMeasurement\n",
    "\n",
    "import pandas as pd\n",
    "range_residuals = pd.DataFrame(columns=['range'])\n",
    "azel_residuals = pd.DataFrame(columns=['az', 'el'])\n",
    "\n",
    "for estMeas, realMeas in zip(estimatedMeasurements, realMeasurements):\n",
    "    #estMeas = EstimatedMeasurement.cast_(estMeas)\n",
    "    estimatedValue = estMeas.getEstimatedValue()\n",
    "    pyDateTime = absolutedate_to_datetime(estMeas.getDate())\n",
    "\n",
    "    if isinstance(realMeas, Range):\n",
    "        observedValue = realMeas.getObservedValue()\n",
    "        range_residuals.loc[pyDateTime] = np.array(observedValue) - np.array(estimatedValue)\n",
    "    elif isinstance(realMeas, AngularAzEl):\n",
    "        observedValue = realMeas.getObservedValue()\n",
    "        azel_residuals.loc[pyDateTime] = np.array(observedValue) - np.array(estimatedValue)\n",
    "\n",
    "display(range_residuals)\n",
    "display(azel_residuals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up Plotly for offline mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.io as pio\n",
    "pio.renderers.default = 'jupyterlab+png'  # Uncomment for interactive plots\n",
    "#pio.renderers.default = 'png'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting range residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objs as go\n",
    "\n",
    "trace = go.Scattergl(\n",
    "    x=range_residuals.index, y=range_residuals['range'],\n",
    "    mode='markers',\n",
    "    name='Range'\n",
    ")\n",
    "\n",
    "data = [trace]\n",
    "\n",
    "layout = go.Layout(\n",
    "    title = 'Range residuals',\n",
    "    xaxis = dict(\n",
    "        title = 'Datetime UTC'\n",
    "    ),\n",
    "    yaxis = dict(\n",
    "        title = 'Range residual (m)'\n",
    "    )\n",
    ")\n",
    "\n",
    "fig = dict(data=data, layout=layout)\n",
    "\n",
    "pio.show(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting angles residuals (if available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objs as go\n",
    "\n",
    "trace_az = go.Scattergl(\n",
    "    x=azel_residuals.index, y=np.rad2deg(azel_residuals['az']),\n",
    "    mode='markers',\n",
    "    name='Azimuth'\n",
    ")\n",
    "\n",
    "trace_el = go.Scattergl(\n",
    "    x=azel_residuals.index, y=np.rad2deg(azel_residuals['el']),\n",
    "    mode='markers',\n",
    "    name='Elevation'\n",
    ")\n",
    "\n",
    "data = [trace_az, trace_el]\n",
    "\n",
    "layout = go.Layout(\n",
    "    title = 'Angle residuals',\n",
    "    xaxis = dict(\n",
    "        title = 'Datetime UTC'\n",
    "    ),\n",
    "    yaxis = dict(\n",
    "        title = 'Angle residual (deg)'\n",
    "    )\n",
    ")\n",
    "\n",
    "fig = dict(data=data, layout=layout)\n",
    "\n",
    "pio.show(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison with CPF\n",
    "The EDC API also provides Consolidated Prediction Files, which contain spacecraft position/velocity in ITRF frame as generated by their orbit determination system. We can compare our orbit determination with the one from the latest CPF prior to the first ranging data used in our orbit determination."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Requesting CPF data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpfList = slr_dl_manager.queryCpfData(\n",
    "                       sat_list[sc_name]['cospar_id'], startCollectionDate - timedelta(days=1))\n",
    "display(cpfList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downloading and parsing CPF data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpfDataFrame = slr_dl_manager.dlAndParseCpfData(\n",
    "                                 [cpfList.index[0]], # If several ephemerides are available for this day, only take the first\n",
    "                                 startCollectionDate - timedelta(days=1),\n",
    "                                 odDate + timedelta(days=1))\n",
    "display(cpfDataFrame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Propagating the solution \n",
    "Propagating the solution and:\n",
    "* Saving the PV coordinates from both the solution and the initial TLE guess.\n",
    "* Computing the difference in LVLH frame between the solution and the initial TLE guess.\n",
    "* Computing the difference in LVLH frame between the solution and the CPF file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Propagating the bounded propagator to retrieve the intermediate states\n",
    "\n",
    "deltaPV_tle_lvlh_dict = {}\n",
    "deltaPV_cpf_lvlh_dict = {}\n",
    "\n",
    "from org.hipparchus.geometry.euclidean.threed import Vector3D\n",
    "\n",
    "date_current = date_start\n",
    "while date_current.compareTo(date_end) <= 0:\n",
    "    datetime_current = absolutedate_to_datetime(date_current)\n",
    "    spacecraftState = bounded_propagator.propagate(date_current)\n",
    "\n",
    "    '''\n",
    "    When getting PV coordinates using the SGP4 propagator in LVLH frame,\n",
    "    it is actually a \"delta\" from the PV coordinates resulting from the orbit determination\n",
    "    because this LVLH frame is centered on the satellite's current position based on the orbit determination\n",
    "    '''\n",
    "    deltaPV_lvlh = sgp4Propagator.getPVCoordinates(date_current, lvlh)\n",
    "    deltaPV_tle_lvlh_dict[datetime_current] = [deltaPV_lvlh.getPosition().getX(),\n",
    "                                                 deltaPV_lvlh.getPosition().getY(),\n",
    "                                                 deltaPV_lvlh.getPosition().getZ(),\n",
    "                                                 deltaPV_lvlh.getPosition().getNorm(),\n",
    "                                                 deltaPV_lvlh.getVelocity().getX(),\n",
    "                                                 deltaPV_lvlh.getVelocity().getY(),\n",
    "                                                 deltaPV_lvlh.getVelocity().getZ(),\n",
    "                                                 deltaPV_lvlh.getVelocity().getNorm()]\n",
    "\n",
    "    pos_cpf_ecef = cpfDataFrame.loc[datetime_current]\n",
    "    ecef2lvlh = ecef.getStaticTransformTo(lvlh, date_current)\n",
    "    delta_pos_cpf_lvlh_vector = ecef2lvlh.transformPosition(Vector3D(float(pos_cpf_ecef['x']),\n",
    "                                                                     float(pos_cpf_ecef['y']),\n",
    "                                                                     float(pos_cpf_ecef['z'])))\n",
    "    deltaPV_cpf_lvlh_dict[datetime_current] = [delta_pos_cpf_lvlh_vector.getX(),\n",
    "                                                 delta_pos_cpf_lvlh_vector.getY(),\n",
    "                                                 delta_pos_cpf_lvlh_vector.getZ(),\n",
    "                                                 delta_pos_cpf_lvlh_vector.getNorm()]\n",
    "\n",
    "    date_current = date_current.shiftedBy(dt)\n",
    "\n",
    "deltaPV_tle_lvlh_df = pd.DataFrame.from_dict(deltaPV_tle_lvlh_dict,\n",
    "                                             columns=['x', 'y', 'z', 'pos_norm', 'vx', 'vy', 'vz', 'vel_norm'],\n",
    "                                             orient='index')\n",
    "\n",
    "deltaPV_cpf_lvlh_df = pd.DataFrame.from_dict(deltaPV_cpf_lvlh_dict,\n",
    "                                             columns=['x', 'y', 'z', 'norm'],\n",
    "                                             orient='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting difference between estimated orbit and CPF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting position difference. The grey area represents the time window where range measurements were used to perform the orbit determination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "# Rectangles to visualise time window for orbit determination.\n",
    "\n",
    "od_window_rectangle =  {\n",
    "    'type': 'rect',\n",
    "    # x-reference is assigned to the x-values\n",
    "    'xref': 'x',\n",
    "    # y-reference is assigned to the plot paper [0,1]\n",
    "    'yref': 'paper',\n",
    "    'x0': startCollectionDate,\n",
    "    'y0': 0,\n",
    "    'x1': odDate,\n",
    "    'y1': 1,\n",
    "    'fillcolor': '#d3d3d3',\n",
    "    'opacity': 0.3,\n",
    "    'line': {\n",
    "        'width': 0,\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objs as go\n",
    "\n",
    "traceX = go.Scattergl(\n",
    "    x = deltaPV_cpf_lvlh_df.index,\n",
    "    y = deltaPV_cpf_lvlh_df['x'],\n",
    "    mode='lines',\n",
    "    name='Cross-track'\n",
    ")\n",
    "\n",
    "traceY = go.Scattergl(\n",
    "    x = deltaPV_cpf_lvlh_df.index,\n",
    "    y = deltaPV_cpf_lvlh_df['y'],\n",
    "    mode='lines',\n",
    "    name='Along track'\n",
    ")\n",
    "\n",
    "traceZ = go.Scattergl(\n",
    "    x = deltaPV_cpf_lvlh_df.index,\n",
    "    y = deltaPV_cpf_lvlh_df['z'],\n",
    "    mode='lines',\n",
    "    name='Out-of-plane'\n",
    ")\n",
    "\n",
    "data = [traceX, traceY, traceZ]\n",
    "\n",
    "layout = go.Layout(\n",
    "    title = 'Delta position between CPF and estimation in LVLH frame',\n",
    "    xaxis = dict(\n",
    "        title = 'Datetime UTC'\n",
    "    ),\n",
    "    yaxis = dict(\n",
    "        title = 'Position difference (m)'\n",
    "    ),\n",
    "    shapes=[od_window_rectangle]\n",
    ")\n",
    "\n",
    "fig = dict(data=data, layout=layout)\n",
    "\n",
    "pio.show(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing own CPF file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A CPF file usually contains 7 days of orbit prediction in ECEF frame with a sample time of 5 minutes, to allow the laser stations to track the satellite.\n",
    "\n",
    "Therefore we have to propagate for 7 days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute MJD days and seconds of day\n",
    "def datetime_to_mjd_days_seconds(le_datetime):\n",
    "    apparent_clock_offset_s = datetime_to_absolutedate(le_datetime).offsetFrom(\n",
    "        mjd_utc_epoch, utc)\n",
    "    days_since_mjd_epoch = int(np.floor(apparent_clock_offset_s / 86400.0))\n",
    "    seconds_of_day = apparent_clock_offset_s - days_since_mjd_epoch * 86400.0\n",
    "    return days_since_mjd_epoch, seconds_of_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_end_cpf = datetime_to_absolutedate(odDate).shiftedBy(7 * 86400.0)\n",
    "\n",
    "PV_ecef_cpf_dict = {}\n",
    "\n",
    "dt = 300.0\n",
    "date_current = datetime_to_absolutedate(odDate)\n",
    "while date_current.compareTo(date_end_cpf) <= 0:\n",
    "    datetime_current = absolutedate_to_datetime(date_current)\n",
    "    spacecraftState = bounded_propagator.propagate(date_current)\n",
    "\n",
    "    PV_ecef_cpf = spacecraftState.getPVCoordinates(ecef)\n",
    "    pos_ecef_cpf = PV_ecef_cpf.getPosition()\n",
    "    vel_ecef_cpf = PV_ecef_cpf.getVelocity()\n",
    "    PV_ecef_cpf_dict[datetime_current] = [\n",
    "        pos_ecef_cpf.getX(),\n",
    "        pos_ecef_cpf.getY(),\n",
    "        pos_ecef_cpf.getZ(),\n",
    "        vel_ecef_cpf.getX(),\n",
    "        vel_ecef_cpf.getY(),\n",
    "        vel_ecef_cpf.getZ()\n",
    "    ]\n",
    "\n",
    "    date_current = date_current.shiftedBy(dt)\n",
    "\n",
    "PV_ecef_cpf_df = pd.DataFrame.from_dict(\n",
    "    PV_ecef_cpf_dict,\n",
    "    columns=['x', 'y', 'z', 'vx', 'vy', 'vz'],\n",
    "    orient='index'\n",
    ")\n",
    "PV_ecef_cpf_df['DateTimeUTC'] = PV_ecef_cpf_df.index\n",
    "PV_ecef_cpf_df['mjd_days'], PV_ecef_cpf_df['seconds_of_day'] = zip(*PV_ecef_cpf_df['DateTimeUTC'].apply(lambda x:\n",
    "                                                                         datetime_to_mjd_days_seconds(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slr_dl_manager.write_cpf(cpf_df=PV_ecef_cpf_df,\n",
    "          cpf_filename='cpf_out.ass',\n",
    "          ephemeris_source='ASS',\n",
    "          production_date=odDate,\n",
    "          ephemeris_sequence=5999,\n",
    "          target_name=sc_name,\n",
    "          cospar_id=sat_list[sc_name]['cospar_id'],\n",
    "          sic=sat_list[sc_name]['sic_id'],\n",
    "          norad_id=str(sat_list[sc_name]['norad_id']),\n",
    "          ephemeris_start_date=odDate,\n",
    "          ephemeris_end_date=absolutedate_to_datetime(date_end_cpf),\n",
    "          step_time=int(dt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison with TLE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the components of the position different between the TLE and the estimation, in LVLH frame. The grey area represents the time window where range measurements were used to perform the orbit determination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objs as go\n",
    "\n",
    "traceX = go.Scattergl(\n",
    "    x = deltaPV_tle_lvlh_df['x'].index,\n",
    "    y = deltaPV_tle_lvlh_df['x'],\n",
    "    mode='lines',\n",
    "    name='Cross-Track'\n",
    ")\n",
    "\n",
    "traceY = go.Scattergl(\n",
    "    x = deltaPV_tle_lvlh_df['y'].index,\n",
    "    y = deltaPV_tle_lvlh_df['y'],\n",
    "    mode='lines',\n",
    "    name='Along-Track'\n",
    ")\n",
    "\n",
    "traceZ = go.Scattergl(\n",
    "    x = deltaPV_tle_lvlh_df['z'].index,\n",
    "    y = deltaPV_tle_lvlh_df['z'],\n",
    "    mode='lines',\n",
    "    name='Out-Of-Plane'\n",
    ")\n",
    "\n",
    "data = [traceX, traceY, traceZ]\n",
    "\n",
    "layout = go.Layout(\n",
    "    title = 'Delta position between TLE and estimation in LVLH frame',\n",
    "    xaxis = dict(\n",
    "        title = 'Datetime UTC'\n",
    "    ),\n",
    "    yaxis = dict(\n",
    "        title = 'Position difference (m)'\n",
    "    ),\n",
    "    shapes=[od_window_rectangle]\n",
    ")\n",
    "\n",
    "fig = dict(data=data, layout=layout)\n",
    "\n",
    "pio.show(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting an \"enhanced\" TLE\n",
    "\n",
    "Moved to https://github.com/GorgiAstro/tle-fitting"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
